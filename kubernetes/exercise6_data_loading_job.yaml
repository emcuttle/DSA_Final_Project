apiVersion: batch/v1
kind: Job
metadata:
  name: exercise6-dataset-validation
spec:
  template:
    spec:
      containers:
      - name: dataset-validation
        image: python:3.9-slim
        command: ["python", "-c"]
        args:
          - |
            print("Project Title: SAR Wildfire Building Damage Detection Model")
            sar_url = "https://capella-open-data.s3.amazonaws.com/data/2025/1/11/CAPELLA_C14_SS_GEO_HH_20250111163649_20250111163705/CAPELLA_C14_SS_GEO_HH_20250111163649_20250111163705.tif"
            fp_url = "https://data.humdata.org/dataset/30768ff0-289b-4fda-96d9-7209243c984d/resource/9650c5fe-c29b-429e-81e3-537688a74f60/download/maxar_palisades_1050010040277500_damage_predictions.gpkg"
            print("SAR Dataset URL:", sar_url)
            print("Footprints URL:", fp_url)

            import urllib.parse
            print("SAR filename:", urllib.parse.urlparse(sar_url).path.split('/')[-1])
            print("Footprint filename:", urllib.parse.urlparse(fp_url).path.split('/')[-1])

            print("Success: Dataset metadata validated.")
        resources:
          requests:
            memory: "50Mi"
            cpu: "50m"
          limits:
            memory: "50Mi"
            cpu: "50m"
      restartPolicy: Never
  backoffLimit: 1
